\documentclass[twocolumn, a4paper, 10pt]{article}  
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{float}
\usepackage{hyperref}
\usepackage{titlesec} 

\geometry{
 a4paper,
 left=15mm,
 right=15mm,
 top=20mm,
 bottom=20mm,
}

\title{\textbf{Practical Work 1: ECG Heartbeat Categorization}}
\author{Nguyen Thi Ngoc Lan \\ Class: Data Science - USTH}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
\hspace{0.3cm}Electrocardiogram (ECG) is a standard tool used in medical practice to identify cardiac abnormalities. This report presents the implementation of a machine learning model to categorize ECG heartbeats using the MIT-BIH Arrhythmia Database. The objective is to classify heartbeats into five distinct categories as defined by the Association for the Advancement of Medical Instrumentation (AAMI).

\section{Dataset Description}
\hspace{0.3cm}The dataset used for this practical work is the \textbf{MIT-BIH Arrhythmia Database} (downloaded from Kaggle).
\begin{itemize}
    \item \textbf{Source:} Kaggle (Heartbeat Categorization Dataset).
    \item \textbf{Train set:} 87,554 samples.
    \item \textbf{Test set:} 21,892 samples.
    \item \textbf{Input Features:} Each sample consists of a time-series signal with 187 discrete time steps.
    \item \textbf{Classes:} The dataset maps to 5 categories:
    \begin{itemize}
        \item 0: Normal (N)
        \item 1: Supraventricular premature beat (SVEB)
        \item 2: Premature ventricular contraction (VEB)
        \item 3: Fusion of ventricular and normal beat (F)
        \item 4: Unclassifiable beat (Q)
    \end{itemize}
\end{itemize}

\section{Methodology}

\subsection{Model Selection}
\hspace{0.3cm}Instead of using Deep Learning (CNN), a classic Machine Learning was experimented: the \textbf{Random Forest Classifier}. 

\textbf{Reason for selection:} Random Forest is an ensemble learning method that fits a number of decision tree classifiers on various sub-samples of the dataset. It is known for high accuracy on tabular/structured data and robustness against overfitting.

\subsection{Implementation Details}
\hspace{0.3cm}The model was implemented using Python and the \texttt{scikit-learn} library.
\begin{itemize}
    \item \textbf{Preprocessing:} The raw 187 time-series points were used directly as features ($X$). No complex signal filtering was applied, demonstrating the model's ability to learn from raw data.
    \item \textbf{Model Architecture:} Random Forest Classifier.
    \item \textbf{Hyperparameters:} 
    \begin{itemize}
        \item \texttt{n\_estimators = 100}: The number of trees in the forest.
        \item \texttt{class\_weight = "balanced"}: This is a crucial parameter used to handle the imbalance in the dataset (since ``Normal" beats vastly outnumber ``Fusion" or ``SVEB" beats).
    \end{itemize}
\end{itemize}

\section{Results and Analysis}

\subsection{Overall Performance}
\hspace{0.3cm}The model was evaluated on the Test set (21,892 samples) and achieved excellent results:
\begin{itemize}
    \item \textbf{Accuracy:} \textbf{97.30\%}
    \item \textbf{Macro Average F1-score:} \textbf{0.86}
    \item \textbf{Weighted Average F1-score:} \textbf{0.97}
\end{itemize}

\subsection{Detailed Classification Report}
\hspace{0.3cm}Below is the detailed performance for each class based on the experiment results:

\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lrrr}
\toprule
\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} \\
\midrule
Normal (0) & 0.97 & 1.00 & 0.98 \\
SVEB (1) & 0.97 & 0.59 & 0.73 \\
VEB (2) & 0.98 & 0.88 & 0.93 \\
Fusion (3) & 0.82 & 0.58 & 0.68 \\
Unknown (4) & 1.00 & 0.94 & 0.97 \\
\bottomrule
\end{tabular}%
}
\caption{Classification Report per Class}
\end{table}

\subsection{Confusion Matrix Visualization}
\hspace{0.3cm}Figure \ref{fig:matrix} visualizes the performance of the model across all classes. It helps identify where the model makes errors (e.g., distinguishing between Fusion beats and Normal beats).

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{confusion_matrix.png} 
    \caption{Confusion Matrix of Random Forest Model on Test Set}
    \label{fig:matrix}
\end{figure}

\subsection{Comparison with Original Paper}
\hspace{0.3cm}According to the dataset description, the original paper using a Convolutional Neural Network (CNN) achieved an accuracy of approximately \textbf{93.4\%}.

The implementation using Random Forest achieved \textbf{97.30\%}, which is higher than the baseline. This suggests that for this specific pre-processed version of the MIT-BIH dataset, ensemble methods like Random Forest can perform exceptionally well without the high computational cost of Deep Learning.

\section{Conclusion}
\hspace{0.3cm}This practical work successfully built a Random Forest model to classify arrhythmia heartbeats. The model reached an accuracy of 97.30\%, surpassing the reference baseline. While the model performs perfectly on Normal beats (Recall = 1.00), it still faces challenges with minority classes like Fusion beats (Recall = 0.58), which could be improved in future work by using more advanced data augmentation techniques.

\end{document}